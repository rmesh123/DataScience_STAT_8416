---
title: "STAT 4410/8416 Homework 2"
author: "Danuwar Ramesh"
date: "Due on October 7, 2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(fig.align='center', message=FALSE, cache=TRUE)
output <- opts_knit$get("rmarkdown.pandoc.to")
if(!is.null(output)) {
  if(output=="html") opts_chunk$set(out.width = '400px') else
    opts_chunk$set(out.width='.6\\linewidth')
}
```

```{r}
library(ggplot2)
library(maps)
library(reshape2)
library(scales)
library(knitr)
library(dplyr)
library(babynames)
```

**1.** The data set `tips` contains tip amounts for different party sizes as well as total bill amounts per payment. We can get the data from the reshape2 package as follows:

```{r}
library(reshape2)
tips.dat <- tips
```

Now answer the following questions:

  a. Compute the tip rate, dividing tip by total bill, and create a new column called `tip.rate` in the dataframe `tips.dat`. Demonstrate your results by showing the head of `tips.dat`.  


```{r}
tips.dat$tip.rate <- with(tips.dat, tip/total_bill)
head(tips.dat)

```

  b. Draw a side-by-side violin plot of the tip rate for each party size. Order the party sizes by the median tip rate. Provide your code as well as your plot. Which party size is responsible for the highest median tip rate?  

  
```{r}
library(ggplot2)
ggplot(tips.dat, aes(reorder(size, tip.rate, median), tip.rate)) +
  geom_violin() 
```
# Which party size is responsible for the highest median tip rate?  2


  c. Generate a similar plot to the one you created in question 2b for each day (instead of party size) and facet by sex and smoker. Is the shape of the violin plot similar for each faceted condition?  
  
  
```{r}
ggplot(tips.dat, aes(reorder(day, tip.rate, median), tip.rate)) +
  geom_violin() +
  facet_grid(sex~smoker) 
```
  
  
**2.** We can generate an $n$x$k$ matrix $M$ and a vector $V$ of length $k$ for some specific values of $n$ and $k$ as follows:
```{r}
set.seed(321)
n <- 9
k <- 5
V <- sample(seq(50), size = k, replace = TRUE)
M <- matrix(rnorm(n * k), ncol = k)
```

  a. Now, carefully review the following for-loop. Rewrite the code so that you perform the same job without a loop.  

```{r}
set.seed(321)
n <- 9
k <- 5
V <- sample(seq(50), size = k, replace = TRUE)
M <- matrix(rnorm(n * k), ncol = k)

X <- M
for(i in seq(n)) {
  X[i, ] <- round(M[i, ] / V, digits = 4)
}


Z <- round(t(t(M) / V), digits = 4)
head(Z)
```

    
  b. Now do the same experiment for $n=900$ and $k=500$. Which runs faster, your code or the for-loop? Demonstrate this using the function `system.time()`.
  
  
  
```{r}
n <- 900
k <- 500
V <- sample(seq(50), size = k, replace = TRUE)
M <- matrix(rnorm(n * k), ncol = k)
X <- M

#Using for loop
system.time(for(i in seq(n)){
  X[1,] <- round(M[1,]/ V, digits=4)
  
})


```
  
#Using no loop
```{r}
n <- 900
k <- 500
V <- sample(seq(50), size = k, replace = TRUE)
M <- matrix(rnorm(n * k), ncol = k)
X <- M

system.time(
  Z <- round(t(t(M) / V), digits = 4)
)
```

  

  
#Therefore, total run time using no loop is shorter than using "for loop". So, my code runs faster than "for loop".
  
  
**3.** We want to generate a plot of US arrest data (USArrests). Please provide the detailed codes to answer the following questions.

  a. Obtain USA state boundary coordinates data for generating a USA map using function `map_data()` and store the data in `mdat`. Display the first few rows of data from `mdat`, noticing that there is a column called `order` that contains the true order of the coordinates.  
```{r}
mdat <- map_data("state")
head(mdat)
```




  b. \label{standardize-rate} You will find USA crime data in the data frame called `USArrests`. Standardize the crime rates and create a new column called `state` so that all state names are in lower case. Store this new data in an object called `arrest` and report the first few rows of `arrest`.  
  
  
```{r}
state<-tolower(row.names(USArrests))
std_crime<-scale(USArrests)
arrest<-data.frame(state,std_crime)
head(arrest)
```
  


  c. \label{order-data} Merge the two data sets `mdat` and `arrest` by state name. Note: merging will change the order of the coordinates data. So, order the data back to the original order and store the merged-ordered data in `odat`. Report the first few rows of data from `odat`.

```{r}
arrestDat <- merge(mdat, arrest, by.x='region', by.y='state', all.x=TRUE)
odat <- arrestDat[order(arrestDat$order),]
head(odat)

```
  

  d. All the columns of `odat` are not necessary for our analysis. So, obtain a subset by selecting only the columns long, lat, group, region, Murder, Assault, UrbanPop, and Rape. Store the data in `sdat` and report the first few rows.
  
```{r}
sdat <- subset(odat, select=c("long", "lat", "group", "region", "Murder",
                              "Assault", "UrbanPop", "Rape" ))
head(sdat)
```
  

  e. Melt the data frame `sdat` with id variables long, lat, group, region. Store the molten data in `msdat` and report the first few rows of data.
  
```{r}
msdat <- melt(sdat, id=c("long", "lat", "group", "region"))
head(msdat)

```
  

  f. \label{plot-crime} The molten data frame `msdat` is now ready to be plotted. Create a plot showing the USA state map, fill by value, and `facet_wrap` with variable. Please don't add any legend and make sure that facetting labels are identified so that we can compare the facetted plots.
  
```{r}

ggplot(msdat, aes(x=long, y=lat, group=group)) +
  geom_polygon(aes(fill=value), colour = alpha("white", 1/2), size = 0.5) +
  theme(legend.position = "none") +
  facet_wrap(~variable) +
  scale_fill_continuous(low="blue", high="yellow")

```
  

  g. Now examine the plot you have generated in question (f) and answer the following questions based on what you see in the plot.  
    \   
    i. For each crime, name two states with its highest rate. 
    
    # Murder:Georgia, Mississippi
    # Assault= North Carolina, Florida
    # Rape= Nevada,California
    
    ii. Do you think a larger urban population is indicative of a higher murder rate? Why or why not?  
    
    According to the data from the above plot crime, i do not think that larger urban population is indicative of a higher murder rate. This is becasue it is clearly shown in the above plot that population density is higher in california where murder rate is higher in georgia and Mississippi. 
    
  h. In question (3b) we standardized the crime rates. Why do you think we did this? Explain what would happen if we did not standardize the data.
 
 We standardized the crime rates in question # 3b because it will make very easy and quick to find the number of each crime rates according to each state.Also, standardizing the crime rates helps to make clear plot of each crime rates.If we did not standardize the data, i think it will be a great mess. It will be very difficult and will take long time to find out the number of crime rates in each state. Also, it will be difficult while making plots.

  i. In question (3c) we ordered the data after merging. Why do you think we had to do this? Explain what would happen if we did not.
  
  We ordered the data after merging .I think we had to do this because we can not do ploting without merging. If we did not do merging, we can still create the map or plot but it will be very confusing and disorder. Also, merging and ordering are correlated which runs one after significantly to make the plot systematic.

**4.** Life expectancy data for four countries can be obtained from the world bank database found at
[github](http://mamajumder.github.io/data-science/data/life-expectancy.csv). It contains life expectancy in years for different genders. Now answer the following questions. 
 
  a. Read the data from the above link and display the first few rows of data. 


```{r}
f <- read.csv("http://mamajumder.github.io/data-science/data/life-expectancy.csv")
head(f)
```

  b. \label{life} Generate a plot showing trend lines of life expectancy by year. Color them by sex and facet by country. Include your code with the plot.

```{r}
b <- melt(data=f, id=c("year", "sex"))
ggplot(b, aes(year, value)) +
  geom_line(aes(color=sex)) +
  facet_wrap(~variable)
```


  c. Explain what interesting features you noticed in the plot you made in question 4b.
#The interesting features which i noticed in the plot made in question 4b are:
 i) Bangladesh, India and Pakistan which all belongs to Asian countries and USA which belongs to North America. It shows  that all the countries shown in the above plot has increasing tread of Life expectancy.
 
 ii) The asian countries shown in the above plot has almost the same life expectancy(male & female) starting around 40s in 1960 whereas the life expectancy(male & female) of USA was around 65 for male and above 70 for female. It shows that the asian countries shown in the above plot has very low life expectancy in comparison to USA since 1960 to 2010.
 
 iii) looking at the above plot, it clearly shows that health conditions of USA is literally way better than the other mentioned countries.

  

**5.** For the following questions please use data frame `tips` 

  a. \label{bar} Create a bar chart that shows the average tip by day.

```{r}
average_tip <- tapply(tips$tip, tips$day, mean)
average_dat <- melt(average_tip)
names(average_dat)[1] <- "day"
names(average_dat)[2] <- "tips"
```

```{r}
ggplot(average_dat, aes(day, tips)) +
  geom_bar(stat="identity", fill="blue", alpha=0.3)
```



  b. Compute the average tip, total tip, and average size grouped by smoker and day. i.e.,  For each combination of smoker and day you should have a row of these summaries. Report these results in a nice table.

```{r}
da <- tips %>%
  group_by(smoker, day) %>%
  summarize(mean(tip), sum(tip), mean(size))
  names(da)[3] <- "Averagetip"
  names(da)[4] <- "Totaltip"
  names(da)[5] <- "Averagesize"
kable(da)
```

  c. \label{bar-facet} Create a bar chart that shows average tip by day, faceted by smoker.

```{r}

ggplot(da, aes(day, Averagetip)) + 
  geom_bar(stat="identity", fill="blue")+ facet_wrap(~da$smoker)

```

  d. In questions 5a and 5c, we plotted a summary of our data which does not show us the whole picture. In practice, we would like to see all of the data. What plot do you suggest would serve a similar purpose to the one in question 5c? In other words, what would be a better plot to show than tips by day, facetted by smoker? Please produce this plot and include your code.
  
  Here, box plot is much better than other plots.
```{r}
ggplot(tips, aes(day, tip)) +
  geom_point() +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = "point") +
  facet_wrap(~smoker)
```
  
  
  
  
**6.** We have the following data set:

```{r}
myDat <- read.csv("http://mamajumder.github.io/data-science/data/reshape-source.csv")
kable(myDat)
```

We want to reshape the data and produce the following output:

| player|variable |   A|   B|   C|
|------:|:--------|---:|---:|---:|
|      1|walking  | 408| 402| 386|
|      1|cycling  |  43|  31|  41|
|      2|walking  | 373| 404| 422|
|      2|cycling  |  53|  41|  30|
|      3|walking  | 403| 393| 422|
|      3|cycling  |  25|  46|  48|

Provide code that will produce this desired output. Demonstrate your answer by displaying the output as well.


```{r}

myDat <- read.csv("http://mamajumder.github.io/data-science/data/reshape-source.csv")
kable(myDat)

myDat <- melt(myDat, id = c("player", "track"))
Dcast <- dcast(myDat, player + variable ~ track)
kable(Dcast)

```

**7.** **Ordering the factor** In class, we have seen how to order factors. Suppose we have the following data about a certain value obtained during particular months of the year;

```{r}
month <- c("July", "June", "September", "May", "October", "August")
value <- c(35, 72, 14, 23, 60, 105)
df <- data.frame(month, value)
```

Now please do the following:  

  a. Convert the month column of dataframe `df` into a factor column. Demonstrate that it is indeed converted into a factor column.  

```{r}

df$month <- factor(df$month)
str(df)

```

Here, is.factor() lets us check if the parameter is a factor or not. It returns TRUE if it is factor and returns FALSE if it is not.


  b. Now generate a bar chart showing the value for different months.  

```{r}
ggplot(df) +
  geom_bar(aes(month, value), stat="identity")
```





  c. Notice the order of the levels of the months is not natural, instead the plot shows the dictionary order. Now, order the bars according to the natural order of the levels of the class (months of the year as they appear in chronological order) and regenerate the bar graph. 
  
```{r}
df$month <- factor(month, levels = c("May", "June", "July", "August", "September", "October"))
ggplot(df) +
  geom_bar(aes(month, value), stat="identity")
```
  





**8.** Install the `babynames` package with `install.packages()`. This package includes data from the Social Security Administration about American baby names over a wide range of years. Generate a plot of the reported proportion of babies born with the name Angelica over time. Do you notice anything odd about the plotted data? (Hint: you should) If so, describe the issue and generate a new plot that adjusts for this problem. Make sure you show both plots along with all code that was used to generate them.

#install the package for the first time
install.packages('babynames')

#load the package
library(babynames)

#print the variable names in the dataset babynames
names(babynames)

#create a subset of data with names Angelica
dat<-subset(babynames,name=="Angelica")

```{r}
library(babynames)
head(babynames)

angelica <- babynames %>%
  filter(name == "Angelica")

ggplot(angelica, aes(year, prop)) +
  geom_point() +
  geom_line() 
```







**9.** **Bonus (2 points)** for undergraduates and mandatory for graduate students. Suppose we have a vector of data as follows:

```{r}
myVector <- c(-15, -10, -5, 0, 5, 10, 15, 20)
```

  a. \label{q.tapply} Using the function `tapply()`, separately compute the means of the first three values, next two values, and the last three values of `myVector`. Show your code. Your result should be: -10.0, 2.5, 15.0.
  
```{r}
vector_indx <- c(1,1,1,2,2,3,3,3)
tapply(myVector, vector_indx, mean)

```
  

  b. Now repeat question 9a, but instead of computing means, you will compute the sum of squares. Again, show your code. Your result should be: 350, 25, 725.  



```{r}
sum_squares <- function(x) sum(x^2)
tapply(myVector, vector_indx, sum_squares)
```




